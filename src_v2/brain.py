# Module Brain (Cerveau)
# G√®re le chargement du mod√®le LLM et la g√©n√©ration de r√©ponses.

import sys
from llama_cpp import Llama
from huggingface_hub import hf_hub_download
import skills  # Import du module de comp√©tences

class Brain:
    def __init__(self, model_repo="TheBloke/Mistral-7B-Instruct-v0.2-GGUF", model_file="mistral-7b-instruct-v0.2.Q4_K_M.gguf"):
        self.model_path = self._download_model(model_repo, model_file)
        print(f"üß† Chargement du mod√®le depuis {self.model_path}...")
        
        # Configuration pour GPU (n_gpu_layers=-1 pour tout mettre sur le GPU)
        # verbose=False pour √©viter de spammer la console
        try:
            self.llm = Llama(
                model_path=self.model_path,
                n_ctx=2048,          # Contexte r√©duit pour √©viter OOM (4096 -> 2048)
                n_gpu_layers=-1,     # Utilise tout le GPU disponible
                verbose=False
            )
            print("‚úÖ Cerveau charg√© (Mode GPU activ√©) !")
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur chargement GPU, tentative CPU... ({e})")
            self.llm = Llama(
                model_path=self.model_path,
                n_ctx=2048,
                n_gpu_layers=0,      # Mode CPU
                verbose=False
            )
            print("‚úÖ Cerveau charg√© (Mode CPU secours) !")

        # D√©finition de la personnalit√© et des outils
        self.system_prompt = """Tu es Jarvis, une IA assistante intelligente et utile connect√©e √† un PC Windows.
Tu dois r√©pondre de mani√®re concise et pr√©cise en fran√ßais.
Tu as la capacit√© d'effectuer des actions r√©elles sur l'ordinateur.

COMMANDES DISPONIBLES :
- Pour ouvrir Google Chrome, r√©ponds UNIQUEMENT : [CMD:open_chrome]
- Pour ouvrir YouTube, r√©ponds UNIQUEMENT : [CMD:open_youtube]

R√àGLES :
1. Si l'utilisateur demande une action list√©e ci-dessus, utilise le code [CMD:...] correspondant.
2. Sinon, r√©ponds normalement √† la question.
3. Ne dis jamais "Je ne peux pas faire √ßa" pour les actions list√©es ci-dessus.
"""

    def _download_model(self, repo_id, filename):
        """T√©l√©charge le mod√®le automatiquement si absent."""
        print(f"üîç V√©rification du mod√®le {filename}...")
        try:
            model_path = hf_hub_download(
                repo_id=repo_id,
                filename=filename,
                local_dir="./models",
                local_dir_use_symlinks=False
            )
            return model_path
        except Exception as e:
            print(f"‚ùå Erreur de t√©l√©chargement : {e}")
            sys.exit(1)

    def think(self, text):
        """G√©n√®re une r√©ponse √† partir du texte utilisateur."""
        # Construction du prompt avec System Prompt (Format Mistral)
        # On injecte le system prompt avant l'instruction utilisateur
        full_prompt = f"[INST] {self.system_prompt}\n\nUtilisateur : {text} [/INST]"
        
        output = self.llm(
            full_prompt,
            max_tokens=512,
            stop=["</s>", "[/INST]"],
            echo=False
        )
        
        response = output['choices'][0]['text'].strip()
        
        # D√©tection et ex√©cution des commandes
        if "[CMD:open_chrome]" in response:
            skills.execute_skill("open_chrome")
            return "J'ouvre Google Chrome pour vous."
        elif "[CMD:open_youtube]" in response:
            skills.execute_skill("open_youtube")
            return "J'ouvre YouTube tout de suite."
            
        return response

    def analyze_intent(self, text):
        """
        Analyse l'intention avec le LLM si les regex ont √©chou√©.
        Retourne un dict {intent, parameters}.
        """
        import json
        import re
        
        prompt = f"""[INST] Tu es le cerveau analytique de Jarvis.
Ton objectif est de comprendre l'intention de l'utilisateur et de la convertir en une commande JSON structur√©e.

INTENTIONS DISPONIBLES :
- open_app : Ouvrir un logiciel/application (param: app_name). Ex: "Lance Photoshop", "Ouvre le truc pour coder".
- close_app : Fermer un logiciel (param: app_name). Ex: "Ferme Discord".
- web_search : Recherche internet (param: query). Ex: "Qui est Elon Musk ?", "Cherche une recette de cr√™pes".
- file_search : Recherche de fichiers (param: query, drive, extension). Ex: "Trouve mon CV.pdf", "Cherche les photos sur le disque D".
- scroll_down / scroll_up : D√©filement (param: amount). Ex: "Descends", "Monte un peu".
- small_talk : Conversation (param: type=greeting|thanks|goodbye|status|unknown).
- unknown : Si tu ne comprends vraiment pas ou si c'est une question g√©n√©rale qui n√©cessite une r√©ponse verbale.

R√àGLES CRITIQUES :
1. R√©ponds UNIQUEMENT avec un JSON valide. RIEN D'AUTRE.
2. Si l'utilisateur demande d'ouvrir une app, essaie de deviner le nom officiel (ex: "le truc pour √©crire" -> "Word" ou "Notepad").
3. Si c'est une question de culture g√©n√©rale ("Quelle est la capitale de la France ?"), utilise l'intention "unknown" pour que je puisse r√©pondre verbalement.

EXEMPLES :
"Lance Chrome s'il te plait" -> {{"intent": "open_app", "parameters": {{"app_name": "Chrome"}}}}
"Fais une recherche sur les chats" -> {{"intent": "web_search", "parameters": {{"query": "les chats"}}}}
"Descends un peu" -> {{"intent": "scroll_down", "parameters": {{}}}}
"Bonjour Jarvis" -> {{"intent": "small_talk", "parameters": {{"type": "greeting"}}}}
"C'est quoi le sens de la vie ?" -> {{"intent": "unknown", "parameters": {{"text": "C'est quoi le sens de la vie ?"}}}}

Phrase utilisateur : "{text}" [/INST]"""

        try:
            output = self.llm(
                prompt,
                max_tokens=128,
                stop=["</s>", "[/INST]"],
                echo=False,
                temperature=0.1 # Tr√®s d√©terministe
            )
            
            response = output['choices'][0]['text'].strip()
            
            # Nettoyage pour extraire le JSON (au cas o√π le LLM bavarde)
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                return json.loads(json_str)
            else:
                return {'intent': 'unknown', 'parameters': {}}
                
        except Exception as e:
            print(f"Erreur analyse LLM : {e}")
            return {'intent': 'unknown', 'parameters': {}}

# Test rapide si ex√©cut√© directement
if __name__ == "__main__":
    brain = Brain()
    print("R√©ponse :", brain.think("Ouvre chrome s'il te plait"))
